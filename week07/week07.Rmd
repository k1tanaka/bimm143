---
title: "week07.Rmd"
author: "Kaito Tanaka"
date: "11/1/2021"
output:
  pdf_document: default
  html_document: default
---
**Start by downloading the data into our R session**

```{r}
#Read the data file
read.csv("WisconsinCancer.csv")
```

Save it as fna.data
```{r}
fna.data <- "WisconsinCancer.csv"
wisc.df <- read.csv(fna.data, row.names=1)
#Use head function to check the table
head(wisc.df)
```


Use wisc.df[,-1] to omit the first column from our data frame because we will not be using it. 
```{r}
wisc.data <- wisc.df[,-1]
```

Create diagnosis vector for later
```{r}
diagnosis <- as.factor(wisc.df[,1])
```

> **Q1: How many observations are in this dataset?**
```{r}
dim(wisc.data)
```
569 observations of 30 variables.

> **Q2. How many of the observations have a malignant diagnosis?**
```{r}
table(diagnosis)
```
212 observations have a malignant diagnosis.

> **Q3. How many variables/features in the data are suffixed with _mean?**
```{r}
colnames(wisc.data)
grep("_mean", colnames(wisc.data))
length(grep("_mean", colnames(wisc.data)))
```
There are 10 variables in the data that are suffixed with _mean.


**Principal Component Analysis (PCA)**

```{r}
# Check column means and standard deviations
colMeans(wisc.data)
apply(wisc.data,2,sd)
```


```{r}
#Perform PCA on wisc.data so that we include a scale to account for variance
wisc.pr <- prcomp(wisc.data, scale=TRUE )
#check a summary 
summary(wisc.pr)
```


> **Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?** 
44.27% of the original variance is captured by PC1.

> **Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?**
3 principal components are required to describe at least 70% of the original variance (PC1, PC2, and PC3).

> **Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?**
7 principal components are required to describe at least 90% of the original variance in the data.


**Interpret PCA**

```{r}
biplot(wisc.pr)
```

**Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?** 
This plot is very difficult to understand, as various points overlap each other, making it hard to differentiate between data points. It also makes it hard to see any of the labels.  

Lets look at this on a standard scatter plot instead
```{r}
plot(wisc.pr$x[,1:2], xlab= "PC1", ylab= "PC2", col= diagnosis)
```

**Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots? ** 

```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], xlab= "PC1", ylab= "PC3", col= diagnosis)
```
Since PC2 accounts for a larger variance in the original data than PC3, the first graph (PC1 vs PC2) seems to have a cleaner separation of the two groups.



**Create ggplot**

```{r}
# Create a data.frame for ggplot
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
# Load the ggplot2 package
library(ggplot2)
# Make a scatter plot colored by diagnosis
ggplot(df) + 
  aes(PC1, PC2, col= diagnosis) + 
  geom_point()
```


Now attempt to explain the variance
```{r}
# Calculate variance of each component
pr.var <-wisc.pr$sdev^2
head(pr.var)
```

Calculate the variance explained by each principal component. 
```{r}
# Variance explained by each principal component: pve
pve <- pr.var / sum(pr.var)
pve
```

Plot the variance explained for each principal component
```{r}
# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o", col = "Blue")
```

Examine on a scree plot as well.
```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```
**Communicating the PCA Results Questions** 

> **Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?**
```{r}
wisc.pr$rotation["concave.points_mean",1]
```


> **Q10. What is the minimum number of principal components required to explain 80% of the variance of the data?**
```{r}
summary(wisc.pr)
```

5 principal components are required to describe at least 80% of the original variance in the data.


**Moving on to Hierarchical Clustering**

Scale the data using "scale()" function. 

```{r}
# Scale the wisc.data data using the "scale()" function
data.scaled <- scale(wisc.data)
```

Calculate the Euclidean distances 

```{r}
data.dist <- dist(data.scaled)
```

Create a hierarchical clustering model using complete linkage. Manually specify the method argument to hclust() and assign the results to wisc.hclust.

```{r}
wisc.hclust <- hclust(data.dist, method = "complete" )
```

> **Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?**
```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```

At a height of 19. 


**Selecting number of clusters**
```{r}
wisc.hclust.clusters <-cutree(wisc.hclust, k=4)
#lets look on a table
table(wisc.hclust.clusters, diagnosis)
```

>**Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?**
```{r}
table(cutree(wisc.hclust, k=2), diagnosis)
```

>**Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.**
```{r}
plot(hclust(data.dist, method= "average"))
plot(hclust(data.dist, method= "single"))
plot(hclust(data.dist, method= "complete"))
plot(hclust(data.dist, method= "ward.D2"))
```

The "ward.D2" method gives me my favorite results. The data seems to be more clear, and is centered.

>**Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?**
table(wisc.hclust.clusters, wisc.km$cluster)

K-means does a very poor job at separating the two diagnoses. K-means yields worse results than hclust. 


**Combine methods and do clustering on our PCA results**

```{r}
wisc.pc.hclust<-hclust(dist(wisc.pr$x[,1:3]), method="ward.D2")
```

Plot the cluster dendrogram 
```{r}
plot(wisc.pc.hclust)
abline(h=70, col="red")
```


Cut the tree in k=2 groups 
```{r}
grps<-cutree(wisc.pc.hclust, k=2)
table(grps)
```


Cross table to compare diagnosis and cluster groups
```{r}
table(diagnosis,grps)
```

Plot "wisc.pr$x"
*We used 1:3 in class to cover more data, although the workbook noted 1:2*

```{r}
plot(wisc.pr$x[,1:3], col=grps)
```


Color the plot by diagnosis
```{r}
plot(wisc.pr$x[,1:3], col=diagnosis)
```

Re-order the groups such that cluster 1 (malignant) is red, and cluster 2 (begnign) is black.
```{r}
g <- as.factor(grps)
g <- relevel(g,2)
levels(g)
```

Now plot with our re-ordered factor.
```{r}
plot(wisc.pr$x[,1:3], col=g)
```

This time, use the data along the first 7 PCs for clustering, while cutting the model into two clusters. 
```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7]), method="ward.D2")
#Cut model into 2 clusters
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
```

Using table(), compare the results from your new hierarchical clustering model with the actual diagnoses.

>**Q15. How well does the newly created model with four clusters separate out the two diagnoses?**
```{r}
# Compare to actual diagnoses
table(wisc.pr.hclust.clusters, diagnosis)
```

The newly created model with four clusters separates out the two diagnoses much better. Most of the malignant diagnoses were grouped into the first cluster, while most benign diagnoses were grouped into the second cluster. 

>**Q16.How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model with the vector containing the actual diagnoses.**
table(wisc.km$cluster, diagnosis)
```{r}
table(wisc.hclust.clusters, diagnosis)
```

K-means produced the worst separation results. There were various data points where malignant diagnoses were wrongly grouped into cluster 2 with the benign diagnoses. 


**Sensitivity/Specificity**

```{r}
table(diagnosis,grps)
```

Accuracy - What proportion did we get correct if we call cluster 1 M and cluster 2 B

```{r}
(333+179)/nrow(wisc.data)
```

Sensitivity - A test’s ability to correctly detect ill patients who do have the condition. In our example, sensitivity is the total number of samples in the cluster identified as predominantly malignant (cancerous) divided by the total number of known malignant samples. In other words: TP/(TP+FN)

```{r}
179/(179+33)
```

Specificity -  a test’s ability to correctly reject healthy patients without a condition. In our example, specificity is the proportion of benign (not cancerous) samples in the cluster identified as predominantly benign that are known to be benign. In other words: TN/(TN+FN)

```{r}
333/(24+333)
```

> **Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?** 

Clustering on PCA results resulted in a clustering model with the best specificity and sensitivity.


**Prediction**

Use predict() to take our PCA model from before and new cancer cell data and project that data onto our PCA space.
```{r}
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```


Plot PCA model.
```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> **Q18. Which of these new patients should we prioritize for follow up based on your results?** 

We should prioritize patient 2, as they are more likely to be be grouped in the malignant diagnosed section. 